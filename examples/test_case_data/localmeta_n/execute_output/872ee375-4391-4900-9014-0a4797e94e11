{
  "uuid" : "872ee375-4391-4900-9014-0a4797e94e11",
  "last_modified" : 1576652806930,
  "version" : "3.0.0.20500",
  "content" : "org.apache.kylin.job.exception.ExecuteException: java.lang.reflect.InvocationTargetException\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:205)\n\tat org.apache.kylin.job.execution.DefaultChainedExecutable.doWork(DefaultChainedExecutable.java:76)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\tat org.apache.kylin.job.impl.threadpool.DefaultScheduler$JobRunner.run(DefaultScheduler.java:114)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.runLocalMode(NSparkExecutable.java:359)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.doWork(NSparkExecutable.java:153)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\t... 6 more\nCaused by: java.lang.RuntimeException: Error execute io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:89)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.main(ResourceDetectBeforeCubingJob.java:99)\n\t... 13 more\nCaused by: java.lang.NullPointerException\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$$anonfun$5.apply(MetadataConverter.scala:87)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$$anonfun$5.apply(MetadataConverter.scala:77)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$.extractEntity(MetadataConverter.scala:77)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$.getSegmentInfo(MetadataConverter.scala:32)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter.getSegmentInfo(MetadataConverter.scala)\n\tat org.apache.kylin.engine.spark.metadata.cube.ManagerHub.getSegmentInfo(ManagerHub.java:35)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.doExecute(ResourceDetectBeforeCubingJob.java:56)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:266)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:86)\n\t... 14 more\n",
  "status" : "ERROR",
  "info" : {
    "startTime" : "1576652772831",
    "buildInstance" : "86928@yimingxumac.local",
    "endTime" : "1576652806929"
  }
}