{
  "uuid" : "50cae1eb-2070-4e67-b045-22b96eb84c99-00",
  "last_modified" : 1576682770648,
  "version" : "3.0.0.20500",
  "content" : "java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.runLocalMode(NSparkExecutable.java:359)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.doWork(NSparkExecutable.java:153)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\tat org.apache.kylin.job.execution.DefaultChainedExecutable.doWork(DefaultChainedExecutable.java:76)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\tat org.apache.kylin.job.impl.threadpool.DefaultScheduler$JobRunner.run(DefaultScheduler.java:114)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: Error execute io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:89)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.main(ResourceDetectBeforeCubingJob.java:99)\n\t... 13 more\nCaused by: org.apache.spark.sql.AnalysisException: cannot resolve '`SELLER_ACCOUNT_0_DOT_0_ACCOUNT_COUNTRY`' given input columns: [TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL2_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_LEAF_CATEG_NAME, SELLER_COUNTRY_0_DOT_0_COUNTRY, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL7_NAME, TEST_CATEGORY_GROUPINGS_0_DOT_0_SAP_CATEGORY_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL6_NAME, TEST_CATEGORY_GROUPINGS_0_DOT_0_USER_DEFINED_FIELD1, TEST_KYLIN_FACT_0_DOT_0_ORDER_ID, TEST_KYLIN_FACT_0_DOT_0_SELLER_ID, SELLER_COUNTRY_0_DOT_0_NAME, SELLER_COUNTRY_0_DOT_0_LATITUDE, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL7_ID, TEST_KYLIN_FACT_0_DOT_0_CAL_DT, TEST_CATEGORY_GROUPINGS_0_DOT_0_LEAF_CATEG_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL3_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_MOVE_TO, TEST_CATEGORY_GROUPINGS_0_DOT_0_GROUPINGS_CRE_DATE, TEST_CATEGORY_GROUPINGS_0_DOT_0_META_CATEG_NAME, TEST_KYLIN_FACT_0_DOT_0_LSTG_SITE_ID, TEST_KYLIN_FACT_0_DOT_0_SLR_SEGMENT_CD, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL4_NAME, TEST_KYLIN_FACT_0_DOT_0_ITEM_COUNT, TEST_KYLIN_FACT_0_DOT_0_LSTG_FORMAT_NAME, TEST_KYLIN_FACT_0_DOT_0_TEST_COUNT_COLUMN, TEST_CATEGORY_GROUPINGS_0_DOT_0_DOMAIN_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_VCS_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_SRC_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_GCS_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL4_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL6_ID, TEST_KYLIN_FACT_0_DOT_0_TEST_COUNT_DISTINCT_BITMAP, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL5_NAME, TEST_CATEGORY_GROUPINGS_0_DOT_0_UPD_DATE, TEST_KYLIN_FACT_0_DOT_0_PRICE, TEST_KYLIN_FACT_0_DOT_0_LEAF_CATEG_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_UPD_USER, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_BUSN_MGR, TEST_CATEGORY_GROUPINGS_0_DOT_0_META_CATEG_ID, TEST_KYLIN_FACT_0_DOT_0_TRANS_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_REGN_CATEG, TEST_CATEGORY_GROUPINGS_0_DOT_0_SITE_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL3_NAME, TEST_CATEGORY_GROUPINGS_0_DOT_0_USER_DEFINED_FIELD3, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_FLAGS, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL5_ID, TEST_CATEGORY_GROUPINGS_0_DOT_0_GROUPINGS_CRE_USER, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_BUSN_UNIT, TEST_CATEGORY_GROUPINGS_0_DOT_0_ADULT_CATEG_YN, SELLER_COUNTRY_0_DOT_0_LONGITUDE, TEST_CATEGORY_GROUPINGS_0_DOT_0_BSNS_VRTCL_NAME, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL2_NAME, TEST_CATEGORY_GROUPINGS_0_DOT_0_USER_DEFINED_FIELD5];;\n'Join Inner, ('SELLER_ACCOUNT_0_DOT_0_ACCOUNT_COUNTRY = SELLER_COUNTRY_0_DOT_0_COUNTRY#1832)\n:- Join Inner, ((TEST_KYLIN_FACT_0_DOT_0_LEAF_CATEG_ID#57L = TEST_CATEGORY_GROUPINGS_0_DOT_0_LEAF_CATEG_ID#1350L) && (TEST_KYLIN_FACT_0_DOT_0_LSTG_SITE_ID#58 = TEST_CATEGORY_GROUPINGS_0_DOT_0_SITE_ID#1352))\n:  :- Project [TEST_KYLIN_FACT_0_DOT_0_TRANS_ID#49L, TEST_KYLIN_FACT_0_DOT_0_ORDER_ID#51L, TEST_KYLIN_FACT_0_DOT_0_CAL_DT#53, TEST_KYLIN_FACT_0_DOT_0_LSTG_FORMAT_NAME#55, TEST_KYLIN_FACT_0_DOT_0_LEAF_CATEG_ID#57L, TEST_KYLIN_FACT_0_DOT_0_LSTG_SITE_ID#58, TEST_KYLIN_FACT_0_DOT_0_SLR_SEGMENT_CD#60, TEST_KYLIN_FACT_0_DOT_0_SELLER_ID#65, TEST_KYLIN_FACT_0_DOT_0_PRICE#68, TEST_KYLIN_FACT_0_DOT_0_ITEM_COUNT#69, TEST_KYLIN_FACT_0_DOT_0_TEST_COUNT_DISTINCT_BITMAP#70, TEST_KYLIN_FACT_0_DOT_0_TEST_COUNT_COLUMN#71]\n:  :  +- Project [TRANS_ID#0L AS TEST_KYLIN_FACT_0_DOT_0_TRANS_ID#49L, ORDER_ID#2L AS TEST_KYLIN_FACT_0_DOT_0_ORDER_ID#51L, CAL_DT#4 AS TEST_KYLIN_FACT_0_DOT_0_CAL_DT#53, LSTG_FORMAT_NAME#6 AS TEST_KYLIN_FACT_0_DOT_0_LSTG_FORMAT_NAME#55, LEAF_CATEG_ID#8L AS TEST_KYLIN_FACT_0_DOT_0_LEAF_CATEG_ID#57L, LSTG_SITE_ID#9 AS TEST_KYLIN_FACT_0_DOT_0_LSTG_SITE_ID#58, SLR_SEGMENT_CD#10 AS TEST_KYLIN_FACT_0_DOT_0_SLR_SEGMENT_CD#60, SELLER_ID#11 AS TEST_KYLIN_FACT_0_DOT_0_SELLER_ID#65, PRICE#12 AS TEST_KYLIN_FACT_0_DOT_0_PRICE#68, ITEM_COUNT#14 AS TEST_KYLIN_FACT_0_DOT_0_ITEM_COUNT#69, TEST_COUNT_DISTINCT_BITMAP#16 AS TEST_KYLIN_FACT_0_DOT_0_TEST_COUNT_DISTINCT_BITMAP#70, TEST_COUNT_COLUMN#18 AS TEST_KYLIN_FACT_0_DOT_0_TEST_COUNT_COLUMN#71]\n:  :     +- SubqueryAlias `TEST_KYLIN_FACT`\n:  :        +- Relation[TRANS_ID#0L,ORDER_ID#2L,CAL_DT#4,LSTG_FORMAT_NAME#6,LEAF_CATEG_ID#8L,LSTG_SITE_ID#9,SLR_SEGMENT_CD#10,SELLER_ID#11,PRICE#12,ITEM_COUNT#14,TEST_COUNT_DISTINCT_BITMAP#16,TEST_COUNT_COLUMN#18] csv\n:  +- Project [TEST_CATEGORY_GROUPINGS_0_DOT_0_LEAF_CATEG_ID#1350L, TEST_CATEGORY_GROUPINGS_0_DOT_0_LEAF_CATEG_NAME#1351, TEST_CATEGORY_GROUPINGS_0_DOT_0_SITE_ID#1352, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_BUSN_MGR#1353, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_BUSN_UNIT#1354, TEST_CATEGORY_GROUPINGS_0_DOT_0_REGN_CATEG#1355, TEST_CATEGORY_GROUPINGS_0_DOT_0_USER_DEFINED_FIELD1#1356, TEST_CATEGORY_GROUPINGS_0_DOT_0_USER_DEFINED_FIELD3#1357, TEST_CATEGORY_GROUPINGS_0_DOT_0_GROUPINGS_CRE_DATE#1358, TEST_CATEGORY_GROUPINGS_0_DOT_0_UPD_DATE#1359, TEST_CATEGORY_GROUPINGS_0_DOT_0_GROUPINGS_CRE_USER#1360, TEST_CATEGORY_GROUPINGS_0_DOT_0_UPD_USER#1361, TEST_CATEGORY_GROUPINGS_0_DOT_0_META_CATEG_ID#1362, TEST_CATEGORY_GROUPINGS_0_DOT_0_META_CATEG_NAME#1363, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL2_ID#1364, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL3_ID#1365, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL4_ID#1366, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL5_ID#1367, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL6_ID#1368, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL7_ID#1369, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL2_NAME#1370, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL3_NAME#1371, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL4_NAME#1372, TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL5_NAME#1373, ... 12 more fields]\n:     +- Project [LEAF_CATEG_ID#1170L AS TEST_CATEGORY_GROUPINGS_0_DOT_0_LEAF_CATEG_ID#1350L, LEAF_CATEG_NAME#1171 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_LEAF_CATEG_NAME#1351, SITE_ID#1172 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_SITE_ID#1352, CATEG_BUSN_MGR#1173 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_BUSN_MGR#1353, CATEG_BUSN_UNIT#1174 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_BUSN_UNIT#1354, REGN_CATEG#1175 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_REGN_CATEG#1355, USER_DEFINED_FIELD1#1176 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_USER_DEFINED_FIELD1#1356, USER_DEFINED_FIELD3#1177 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_USER_DEFINED_FIELD3#1357, GROUPINGS_CRE_DATE#1178 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_GROUPINGS_CRE_DATE#1358, UPD_DATE#1179 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_UPD_DATE#1359, GROUPINGS_CRE_USER#1180 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_GROUPINGS_CRE_USER#1360, UPD_USER#1181 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_UPD_USER#1361, META_CATEG_ID#1182 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_META_CATEG_ID#1362, META_CATEG_NAME#1183 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_META_CATEG_NAME#1363, CATEG_LVL2_ID#1184 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL2_ID#1364, CATEG_LVL3_ID#1185 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL3_ID#1365, CATEG_LVL4_ID#1186 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL4_ID#1366, CATEG_LVL5_ID#1187 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL5_ID#1367, CATEG_LVL6_ID#1188 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL6_ID#1368, CATEG_LVL7_ID#1189 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL7_ID#1369, CATEG_LVL2_NAME#1190 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL2_NAME#1370, CATEG_LVL3_NAME#1191 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL3_NAME#1371, CATEG_LVL4_NAME#1193 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL4_NAME#1372, CATEG_LVL5_NAME#1194 AS TEST_CATEGORY_GROUPINGS_0_DOT_0_CATEG_LVL5_NAME#1373, ... 12 more fields]\n:        +- SubqueryAlias `TEST_CATEGORY_GROUPINGS`\n:           +- Relation[LEAF_CATEG_ID#1170L,LEAF_CATEG_NAME#1171,SITE_ID#1172,CATEG_BUSN_MGR#1173,CATEG_BUSN_UNIT#1174,REGN_CATEG#1175,USER_DEFINED_FIELD1#1176,USER_DEFINED_FIELD3#1177,GROUPINGS_CRE_DATE#1178,UPD_DATE#1179,GROUPINGS_CRE_USER#1180,UPD_USER#1181,META_CATEG_ID#1182,META_CATEG_NAME#1183,CATEG_LVL2_ID#1184,CATEG_LVL3_ID#1185,CATEG_LVL4_ID#1186,CATEG_LVL5_ID#1187,CATEG_LVL6_ID#1188,CATEG_LVL7_ID#1189,CATEG_LVL2_NAME#1190,CATEG_LVL3_NAME#1191,CATEG_LVL4_NAME#1193,CATEG_LVL5_NAME#1194,... 12 more fields] csv\n+- Project [SELLER_COUNTRY_0_DOT_0_COUNTRY#1832, SELLER_COUNTRY_0_DOT_0_LATITUDE#1833, SELLER_COUNTRY_0_DOT_0_LONGITUDE#1834, SELLER_COUNTRY_0_DOT_0_NAME#1835]\n   +- Project [COUNTRY#1820 AS SELLER_COUNTRY_0_DOT_0_COUNTRY#1832, LATITUDE#1821 AS SELLER_COUNTRY_0_DOT_0_LATITUDE#1833, LONGITUDE#1822 AS SELLER_COUNTRY_0_DOT_0_LONGITUDE#1834, NAME#1823 AS SELLER_COUNTRY_0_DOT_0_NAME#1835]\n      +- SubqueryAlias `SELLER_COUNTRY`\n         +- Relation[COUNTRY#1820,LATITUDE#1821,LONGITUDE#1822,NAME#1823] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:110)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:275)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:117)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3410)\n\tat org.apache.spark.sql.Dataset.join(Dataset.scala:995)\n\tat io.kyligence.kap.engine.spark.builder.CreateFlatTable$.joinTableDataset(CreateFlatTable.scala:191)\n\tat io.kyligence.kap.engine.spark.builder.CreateFlatTable$$anonfun$joinFactTableWithLookupTables$1.apply(CreateFlatTable.scala:165)\n\tat io.kyligence.kap.engine.spark.builder.CreateFlatTable$$anonfun$joinFactTableWithLookupTables$1.apply(CreateFlatTable.scala:164)\n\tat scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n\tat scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n\tat scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221)\n\tat scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)\n\tat scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104)\n\tat io.kyligence.kap.engine.spark.builder.CreateFlatTable$.joinFactTableWithLookupTables(CreateFlatTable.scala:163)\n\tat io.kyligence.kap.engine.spark.builder.CreateFlatTable.generateDataset(CreateFlatTable.scala:68)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser.getFlatTable(ParentSourceChooser.scala:163)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser.io$kyligence$kap$engine$spark$job$ParentSourceChooser$$decideFlatTableSource(ParentSourceChooser.scala:73)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser$$anonfun$decideSources$1.apply(ParentSourceChooser.scala:59)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser$$anonfun$decideSources$1.apply(ParentSourceChooser.scala:54)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser.decideSources(ParentSourceChooser.scala:54)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.doExecute(ResourceDetectBeforeCubingJob.java:60)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:266)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:86)\n\t... 14 more\n",
  "status" : "ERROR",
  "info" : {
    "startTime" : "1576682761034",
    "endTime" : "1576682770643"
  }
}