{
  "uuid" : "9998637e-9820-43b7-9b8f-2d801438c8a0",
  "last_modified" : 1576682092170,
  "version" : "3.0.0.20500",
  "content" : "org.apache.kylin.job.exception.ExecuteException: java.lang.reflect.InvocationTargetException\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:205)\n\tat org.apache.kylin.job.execution.DefaultChainedExecutable.doWork(DefaultChainedExecutable.java:76)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\tat org.apache.kylin.job.impl.threadpool.DefaultScheduler$JobRunner.run(DefaultScheduler.java:114)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.runLocalMode(NSparkExecutable.java:359)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.doWork(NSparkExecutable.java:153)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\t... 6 more\nCaused by: java.lang.RuntimeException: Error execute io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:89)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.main(ResourceDetectBeforeCubingJob.java:99)\n\t... 13 more\nCaused by: java.util.NoSuchElementException: key not found: TEST_KYLIN_FACT\n\tat scala.collection.MapLike$class.default(MapLike.scala:228)\n\tat scala.collection.AbstractMap.default(Map.scala:59)\n\tat scala.collection.MapLike$class.apply(MapLike.scala:141)\n\tat scala.collection.AbstractMap.apply(Map.scala:59)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$$anonfun$extractJoinTable$2.apply(MetadataConverter.scala:69)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$$anonfun$extractJoinTable$2.apply(MetadataConverter.scala:69)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.mutable.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:46)\n\tat scala.collection.SetLike$class.map(SetLike.scala:92)\n\tat scala.collection.mutable.AbstractSet.map(Set.scala:46)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$.extractJoinTable(MetadataConverter.scala:69)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter$.getSegmentInfo(MetadataConverter.scala:39)\n\tat org.apache.kylin.engine.spark.metadata.MetadataConverter.getSegmentInfo(MetadataConverter.scala)\n\tat org.apache.kylin.engine.spark.metadata.cube.ManagerHub.getSegmentInfo(ManagerHub.java:37)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.doExecute(ResourceDetectBeforeCubingJob.java:56)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:266)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:86)\n\t... 14 more\n",
  "status" : "ERROR",
  "info" : {
    "startTime" : "1576682092024",
    "buildInstance" : "4353@yimingxumac.local",
    "endTime" : "1576682092169"
  }
}