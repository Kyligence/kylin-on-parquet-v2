{
  "uuid" : "32fe5f79-4058-4037-8bea-1995d348c813-00",
  "last_modified" : 1576683788765,
  "version" : "3.0.0.20500",
  "content" : "java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.runLocalMode(NSparkExecutable.java:359)\n\tat io.kyligence.kap.engine.spark.job.NSparkExecutable.doWork(NSparkExecutable.java:153)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\tat org.apache.kylin.job.execution.DefaultChainedExecutable.doWork(DefaultChainedExecutable.java:76)\n\tat org.apache.kylin.job.execution.AbstractExecutable.execute(AbstractExecutable.java:190)\n\tat org.apache.kylin.job.impl.threadpool.DefaultScheduler$JobRunner.run(DefaultScheduler.java:114)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: Error execute io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:89)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.main(ResourceDetectBeforeCubingJob.java:99)\n\t... 13 more\nCaused by: java.lang.IllegalArgumentException: Illegal pattern component: XXX\n\tat org.apache.commons.lang3.time.FastDateFormat.parsePattern(FastDateFormat.java:577)\n\tat org.apache.commons.lang3.time.FastDateFormat.init(FastDateFormat.java:444)\n\tat org.apache.commons.lang3.time.FastDateFormat.<init>(FastDateFormat.java:437)\n\tat org.apache.commons.lang3.time.FastDateFormat$1.createInstance(FastDateFormat.java:110)\n\tat org.apache.commons.lang3.time.FastDateFormat$1.createInstance(FastDateFormat.java:109)\n\tat org.apache.commons.lang3.time.FormatCache.getInstance(FormatCache.java:82)\n\tat org.apache.commons.lang3.time.FastDateFormat.getInstance(FastDateFormat.java:205)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVOptions.<init>(CSVOptions.scala:139)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVOptions.<init>(CSVOptions.scala:41)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:105)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$class.buildReaderWithPartitionValues(FileFormat.scala:129)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:165)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:314)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:312)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDDs(DataSourceScanExec.scala:332)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:613)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:296)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3387)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectAsList$1.apply(Dataset.scala:2798)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectAsList$1.apply(Dataset.scala:2797)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3368)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$2.apply(SQLExecution.scala:87)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:135)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3367)\n\tat org.apache.spark.sql.Dataset.collectAsList(Dataset.scala:2797)\n\tat io.kyligence.kap.engine.spark.mockup.CsvSource$1.getSourceData(CsvSource.java:44)\n\tat io.kyligence.kap.engine.spark.utils.SparkDataSource$SparkSource.table(SparkDataSource.scala:33)\n\tat io.kyligence.kap.engine.spark.builder.CreateFlatTable$.io$kyligence$kap$engine$spark$builder$CreateFlatTable$$generateTableDataset(CreateFlatTable.scala:124)\n\tat io.kyligence.kap.engine.spark.builder.CreateFlatTable.generateDataset(CreateFlatTable.scala:47)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser.getFlatTable(ParentSourceChooser.scala:163)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser.io$kyligence$kap$engine$spark$job$ParentSourceChooser$$decideFlatTableSource(ParentSourceChooser.scala:73)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser$$anonfun$decideSources$1.apply(ParentSourceChooser.scala:59)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser$$anonfun$decideSources$1.apply(ParentSourceChooser.scala:54)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat io.kyligence.kap.engine.spark.job.ParentSourceChooser.decideSources(ParentSourceChooser.scala:54)\n\tat io.kyligence.kap.engine.spark.job.ResourceDetectBeforeCubingJob.doExecute(ResourceDetectBeforeCubingJob.java:60)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:266)\n\tat io.kyligence.kap.engine.spark.application.SparkApplication.execute(SparkApplication.java:86)\n\t... 14 more\n",
  "status" : "ERROR",
  "info" : {
    "startTime" : "1576683688218",
    "endTime" : "1576683788762"
  }
}